# LangGraph FastAPI Integration - Intelligent RAG Agent

A sophisticated AI agent system that integrates LangGraph with FastAPI to provide intelligent routing between Retrieval-Augmented Generation (RAG), web search, and direct answering capabilities. This project demonstrates advanced conversational AI with context-aware decision making.

## ğŸ“º Tutorial Series

This repository is part of a comprehensive tutorial series on building intelligent AI agents:

### Part 1: LangGraph RAG Agent Basics
**[LangGraph RAG Agent Tutorial | Basics to Advanced Multi-Agent AI Chatbot](https://youtu.be/60XDTWhklLA)**

Learn the fundamentals of building a LangGraph RAG agent from scratch, covering:
- LangGraph basics and workflow design
- Multi-agent architecture
- RAG implementation with vector stores
- Advanced routing and decision making

### Part 2: FastAPI Integration & Production Setup
**[Integrating LangGraph RAG Agent with FastAPI | Production Setup with Sessions, History, Vector DB](https://youtu.be/t209A887UpY)**

This repository contains the code for Part 2, focusing on:
- FastAPI integration for production deployment
- Session management and conversation history
- Vector database setup and management
- Document upload and indexing
- API endpoints and testing

## ğŸš€ Features

- **ğŸ§  Intelligent Routing**: Automatic decision-making between RAG, web search, and direct answering
- **ğŸ“š RAG Integration**: Advanced document search using Chroma vector store with contextual query reformulation
- **ğŸŒ Web Search**: Real-time information retrieval using Tavily API
- **ğŸ’¬ Session Management**: Persistent conversation history across requests
- **ğŸ“„ Document Management**: Upload, index, list, and delete documents
- **ğŸ” Contextual Query Processing**: Smart query reformulation for follow-up questions
- **ğŸ“Š Comprehensive Logging**: Detailed logging for debugging and analysis
- **ğŸ—ï¸ Modular Architecture**: Clean separation of concerns with dedicated modules

## ğŸ—ï¸ Architecture Overview

The system uses a sophisticated LangGraph workflow with four main nodes:

```
User Query â†’ Router â†’ [RAG | Web Search | Direct Answer] â†’ Response
```

![Agent Architecture](rag%20agent%20flow%20minimal.png)

### Core Components

1. **Router Node**: Analyzes queries and routes to appropriate handler
2. **RAG Node**: Searches document knowledge base with intelligent judging
3. **Web Search Node**: Performs real-time web searches
4. **Answer Node**: Synthesizes information into coherent responses

## ğŸ“‹ Prerequisites

- Python 3.8+
- OpenAI API Key
- Tavily API Key (for web search functionality)
- Git

## ğŸ› ï¸ Installation & Setup

### 1. Clone the Repository

```bash
git clone <repository-url>
cd LangGraph-FastAPI-Integration
```

### 2. Install Dependencies

Using `uv` (recommended):
```bash
pip install uv
uv pip install -r api/requirements.txt
```

Or using pip:
```bash
pip install -r api/requirements.txt
```

### 3. Environment Configuration

Create a `.env` file in the `api` directory:

```env
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
```

### 4. Initialize the Application

The database and vector store will be created automatically on first run.

## ğŸš€ Running the Application

### Development Server

```bash
cd api
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Production Server

```bash
cd api
uvicorn main:app --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`

## ğŸ“š API Documentation

### Interactive API Docs

Once running, visit:
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

## ğŸ”Œ API Endpoints

### 1. Chat Endpoint

**POST** `/chat`

The main conversational endpoint using the intelligent LangGraph agent.

**Request Body:**
```json
{
  "question": "What is the GreenGrow EcoHarvest System?",
  "session_id": "user-123",
  "model": "gpt-4.1-mini"
}
```

**Response:**
```json
{
  "answer": "The GreenGrow EcoHarvest System is an innovative farming solution...",
  "session_id": "user-123",
  "model": "gpt-4.1-mini"
}
```

**Features:**
- Automatic query contextualization for follow-up questions
- Intelligent routing based on query type
- Session-based conversation history
- Multiple model support

### 2. Document Management

#### Upload Document
**POST** `/upload-doc`

Upload and index documents for RAG functionality.

```bash
curl -X POST "http://localhost:8000/upload-doc" \
  -F "file=@your_document.pdf"
```

**Supported Formats:** PDF, DOCX, HTML

#### List Documents
**GET** `/list-docs`

Retrieve all uploaded documents.

```bash
curl -X GET "http://localhost:8000/list-docs"
```

#### Delete Document
**POST** `/delete-doc`

Remove documents from the system.

```bash
curl -X POST "http://localhost:8000/delete-doc" \
  -H "Content-Type: application/json" \
  -d '{"file_id": 1}'
```



## ğŸ“ Project Structure

```
LangGraph FastAPI Integration/
â”œâ”€â”€ api/                          # Main application directory
â”‚   â”œâ”€â”€ main.py                   # FastAPI application with endpoints
â”‚   â”œâ”€â”€ langgraph_agent.py        # LangGraph agent definition
â”‚   â”œâ”€â”€ nodes.py                  # Agent node implementations
â”‚   â”œâ”€â”€ tools.py                  # RAG and web search tools
â”‚   â”œâ”€â”€ pydantic_models.py        # API request/response models
â”‚   â”œâ”€â”€ db_utils.py               # Database operations
â”‚   â”œâ”€â”€ chroma_utils.py           # Chroma vector store operations
â”‚   â”œâ”€â”€ langchain_utils.py        # LangChain utilities
â”‚   â”œâ”€â”€ shared.py                 # Shared configurations and types
â”‚   â”œâ”€â”€ utils.py                  # Utility functions
â”‚   â”œâ”€â”€ test_agent.py             # Agent testing script
â”‚   â”œâ”€â”€ test_api.py               # API testing script
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ README.md                 # API documentation
â”‚   â”œâ”€â”€ rag_app.db                # SQLite database
â”‚   â”œâ”€â”€ app.log                   # Application logs
â”‚   â””â”€â”€ chroma_db/                # Vector store directory
â”œâ”€â”€ docs/                         # Sample documents for testing
â”‚   â”œâ”€â”€ Company_ GreenFields BioTech.docx
â”‚   â”œâ”€â”€ Company_ QuantumNext Systems.docx
â”‚   â”œâ”€â”€ Company_ TechWave Innovations.docx
â”‚   â”œâ”€â”€ GreenGrow Innovations_ Company History.docx
â”‚   â””â”€â”€ GreenGrow's EcoHarvest System_ A Revolution in Farming.pdf
â”œâ”€â”€ RAG_AI_Agent_using_LangGraph.ipynb  # Original Jupyter notebook
â””â”€â”€ README.md                     # This file
```

## ğŸ”„ Agent Workflow

### 1. Query Processing
- User submits question
- System contextualizes query using chat history
- Router analyzes and determines optimal path

### 2. Routing Decision
- **`end`**: Greetings/small talk â†’ Direct response
- **`rag`**: Document queries â†’ Knowledge base search
- **`answer`**: General questions â†’ Direct AI response

### 3. Information Retrieval
- **RAG Node**: Searches uploaded documents
- **Web Search Node**: Retrieves current information
- **Intelligent Judging**: Determines if RAG results are sufficient

### 4. Response Generation
- Synthesizes information from multiple sources
- Generates coherent, contextual responses
- Maintains conversation history

## ğŸ’¡ Usage Examples

### Example 1: Document Query
```json
{
  "question": "What is the GreenGrow EcoHarvest System?",
  "session_id": "user-123"
}
```
**Flow**: `router` â†’ `rag` â†’ `answer`

### Example 2: Follow-up Question
```json
{
  "question": "When was it introduced?",
  "session_id": "user-123"
}
```
**Flow**: Contextualization â†’ `router` â†’ `rag` â†’ `answer`

### Example 3: Current Events
```json
{
  "question": "What's the latest news about AI developments?",
  "session_id": "user-123"
}
```
**Flow**: `router` â†’ `rag` â†’ `web` â†’ `answer`

### Example 4: Simple Question
```json
{
  "question": "What is the capital of France?",
  "session_id": "user-123"
}
```
**Flow**: `router` â†’ `answer`

## ğŸ—„ï¸ Database Schema

### Chat History Table
Tracks all user interactions for conversation continuity.

| Column | Type | Description |
|--------|------|-------------|
| `id` | INTEGER | Primary key, auto-increment |
| `session_id` | TEXT | Conversation session identifier |
| `user_query` | TEXT | User's question |
| `gpt_response` | TEXT | AI model response |
| `model` | TEXT | AI model used |
| `created_at` | TIMESTAMP | Timestamp of interaction |

### Document Store Table
Manages uploaded documents for RAG functionality.

| Column | Type | Description |
|--------|------|-------------|
| `id` | INTEGER | Primary key, auto-increment |
| `filename` | TEXT | Document filename |
| `upload_timestamp` | TIMESTAMP | Upload timestamp |

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENAI_API_KEY` | OpenAI API key for LLM access | Yes |
| `TAVILY_API_KEY` | Tavily API key for web search | No* |

*Required for web search functionality

### Model Options

- `gpt-4.1`: Full GPT-4 model for complex queries
- `gpt-4.1-mini`: Optimized model for faster responses

## ğŸ› Troubleshooting

### Common Issues

1. **Missing API Keys**
   ```
   Error: OpenAI API key not found
   Solution: Set OPENAI_API_KEY in .env file
   ```

2. **Tavily Search Errors**
   ```
   Error: Tavily API key required for web search
   Solution: Set TAVILY_API_KEY or disable web search
   ```

3. **Chroma Vector Store Issues**
   ```
   Error: Vector store not found
   Solution: Vector store is auto-created in ./chroma_db
   ```

4. **Database Errors**
   ```
   Error: Database connection failed
   Solution: SQLite database is auto-created
   ```

### Logs

Check `api/app.log` for detailed application logs and debugging information.

## ğŸ”’ Security Considerations

- Store API keys in environment variables
- Validate file uploads (type and size)
- Implement rate limiting for production
- Use HTTPS in production environments
- Regular security updates for dependencies

## ğŸš€ Performance Optimization

- Use `gpt-4.1-mini` for faster responses
- Implement caching for frequent queries
- Optimize vector store queries
- Monitor memory usage with large document sets

**Happy coding! ğŸš€** 