{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Youtube: Course Sentence Transformers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Sentence Transformers</h2>"
      ],
      "metadata": {
        "id": "SjNAmtyUT33o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resources:**\n",
        "\n",
        "*   https://www.sbert.net/index.html\n",
        "*   https://www.sbert.net/docs/pretrained_models.html\n",
        "\n"
      ],
      "metadata": {
        "id": "PC08IHg2jNe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use cases:**\n",
        "\n",
        "\n",
        "\n",
        "*   Sentence Embedding\n",
        "*   Sentence Similarity\n",
        "*   Semantic Search\n",
        "*   Clustering\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJ9U2MTSQCGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "iBxOfXwbeurS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Embeding**"
      ],
      "metadata": {
        "id": "8Fe3mt_jCTL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer,util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "QXuwDrEsTl-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03fm2wdZejPc"
      },
      "outputs": [],
      "source": [
        "sentences = ['This framework generates embeddings for each input sentence',\n",
        "    'Sentences are passed as a list of string.']\n",
        "\n",
        "\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "\n",
        "for sentence, embedding in zip(sentences, embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", embedding)\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cosine-Similarity**"
      ],
      "metadata": {
        "id": "YDc8_VCrCQGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb1 = model.encode(\"I am eating Apple\")\n",
        "emb2 = model.encode(\"I like fruits\")\n",
        "cos_sim = util.cos_sim(emb1, emb2)\n",
        "print(\"Cosine-Similarity:\", cos_sim)"
      ],
      "metadata": {
        "id": "ZGz3bDLhewrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14d7c3c-638a-4975-e70c-370d8a61ca03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine-Similarity: tensor([[0.5398]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute cosine similarity between all pairs**"
      ],
      "metadata": {
        "id": "Ml5sIVHOCY6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute cosine similarity between all pairs\n",
        "\n",
        "sentences = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'A man is riding a horse.',\n",
        "          'A woman is playing violin.',\n",
        "          'Two men pushed carts through the woods.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'Someone in a gorilla costume is playing a set of drums.'\n",
        "          ]\n",
        "\n",
        "#Encode all sentences\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "#Compute cosine similarity between all pairs\n",
        "cos_sim = util.cos_sim(embeddings, embeddings)\n",
        "\n",
        "cos_sim\n",
        "\n"
      ],
      "metadata": {
        "id": "9lyr6Tjge9UY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b57e4d-0c3d-435e-8b4f-25eda073c88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  0.7553, -0.1050,  0.2474, -0.0704, -0.0333,  0.1707,  0.0476,\n",
              "          0.0630],\n",
              "        [ 0.7553,  1.0000, -0.0610,  0.1442, -0.0809, -0.0216,  0.1157,  0.0362,\n",
              "          0.0216],\n",
              "        [-0.1050, -0.0610,  1.0000, -0.1088,  0.0217, -0.0413, -0.0928,  0.0231,\n",
              "          0.0247],\n",
              "        [ 0.2474,  0.1442, -0.1088,  1.0000, -0.0348,  0.0362,  0.7369,  0.0821,\n",
              "          0.1389],\n",
              "        [-0.0704, -0.0809,  0.0217, -0.0348,  1.0000, -0.1654, -0.0592,  0.1961,\n",
              "          0.2564],\n",
              "        [-0.0333, -0.0216, -0.0413,  0.0362, -0.1654,  1.0000,  0.0769, -0.0380,\n",
              "         -0.0895],\n",
              "        [ 0.1707,  0.1157, -0.0928,  0.7369, -0.0592,  0.0769,  1.0000,  0.0495,\n",
              "          0.1191],\n",
              "        [ 0.0476,  0.0362,  0.0231,  0.0821,  0.1961, -0.0380,  0.0495,  1.0000,\n",
              "          0.6433],\n",
              "        [ 0.0630,  0.0216,  0.0247,  0.1389,  0.2564, -0.0895,  0.1191,  0.6433,\n",
              "          1.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add all pairs to a list with their cosine similarity score\n",
        "all_sentence_combinations = []\n",
        "for i in range(len(cos_sim)-1):\n",
        "    for j in range(i+1, len(cos_sim)):\n",
        "        all_sentence_combinations.append((cos_sim[i][j], i, j))\n",
        "all_sentence_combinations        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06H7O06b91_q",
        "outputId": "ecf163db-0c42-4ebe-9a3f-9f5b6f900272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor(0.7553), 0, 1),\n",
              " (tensor(-0.1050), 0, 2),\n",
              " (tensor(0.2474), 0, 3),\n",
              " (tensor(-0.0704), 0, 4),\n",
              " (tensor(-0.0333), 0, 5),\n",
              " (tensor(0.1707), 0, 6),\n",
              " (tensor(0.0476), 0, 7),\n",
              " (tensor(0.0630), 0, 8),\n",
              " (tensor(-0.0610), 1, 2),\n",
              " (tensor(0.1442), 1, 3),\n",
              " (tensor(-0.0809), 1, 4),\n",
              " (tensor(-0.0216), 1, 5),\n",
              " (tensor(0.1157), 1, 6),\n",
              " (tensor(0.0362), 1, 7),\n",
              " (tensor(0.0216), 1, 8),\n",
              " (tensor(-0.1088), 2, 3),\n",
              " (tensor(0.0217), 2, 4),\n",
              " (tensor(-0.0413), 2, 5),\n",
              " (tensor(-0.0928), 2, 6),\n",
              " (tensor(0.0231), 2, 7),\n",
              " (tensor(0.0247), 2, 8),\n",
              " (tensor(-0.0348), 3, 4),\n",
              " (tensor(0.0362), 3, 5),\n",
              " (tensor(0.7369), 3, 6),\n",
              " (tensor(0.0821), 3, 7),\n",
              " (tensor(0.1389), 3, 8),\n",
              " (tensor(-0.1654), 4, 5),\n",
              " (tensor(-0.0592), 4, 6),\n",
              " (tensor(0.1961), 4, 7),\n",
              " (tensor(0.2564), 4, 8),\n",
              " (tensor(0.0769), 5, 6),\n",
              " (tensor(-0.0380), 5, 7),\n",
              " (tensor(-0.0895), 5, 8),\n",
              " (tensor(0.0495), 6, 7),\n",
              " (tensor(0.1191), 6, 8),\n",
              " (tensor(0.6433), 7, 8)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sort list by the highest cosine similarity score\n",
        "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "print(\"Top-5 most similar pairs:\")\n",
        "for score, i, j in all_sentence_combinations[0:5]:\n",
        "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))"
      ],
      "metadata": {
        "id": "qhggYpNbfK4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d486f0-4435-4513-8b01-f99f59946370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-5 most similar pairs:\n",
            "A man is eating food. \t A man is eating a piece of bread. \t 0.7553\n",
            "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.7369\n",
            "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.6433\n",
            "A woman is playing violin. \t Someone in a gorilla costume is playing a set of drums. \t 0.2564\n",
            "A man is eating food. \t A man is riding a horse. \t 0.2474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Semantic search**"
      ],
      "metadata": {
        "id": "E0-VolFWK-Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('clips/mfaq')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpX-L96mTthR",
        "outputId": "e4ff82e3-aac0-4853-df35-17df034ffcaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "question = \"<Q>How many models can I host on HuggingFace?\"\n",
        "answer_1 = \"<A>All plans come with unlimited private models and datasets.\"\n",
        "answer_2 = \"<A>AutoNLP is an automatic way to train and deploy state-of-the-art NLP models, seamlessly integrated with the Hugging Face ecosystem.\"\n",
        "answer_3 = \"<A>Based on how much training data and model variants are created, we send you a compute cost and payment link - as low as $10 per job.\"\n",
        "\n",
        "query_embedding = model.encode(question)\n",
        "corpus_embeddings = model.encode([answer_1, answer_2, answer_3])\n",
        "\n",
        "print(util.semantic_search(query_embedding, corpus_embeddings))"
      ],
      "metadata": {
        "id": "z1gio-Pci9RF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c45c533-ade1-469c-8d16-75248660302a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'corpus_id': 0, 'score': 0.5646325945854187}, {'corpus_id': 2, 'score': 0.5142340660095215}, {'corpus_id': 1, 'score': 0.4730038046836853}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "6FG1WXOudgYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_model = pipeline(\"question-answering\")\n",
        "question = \"How many models can I host on HuggingFace?\"\n",
        "context = \"All plans come with unlimited private models and datasets.\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qa18QF-ddMa",
        "outputId": "440e262a-1672-4f9b-e85b-c98bd1f96344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'unlimited', 'end': 29, 'score': 0.701717734336853, 'start': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(util.semantic_search(query_embedding, corpus_embeddings))"
      ],
      "metadata": {
        "id": "_J6IY-4oC4hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clustering**"
      ],
      "metadata": {
        "id": "G9tF0hu6K0TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Corpus with example sentences\n",
        "corpus = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'Horse is eating grass.',\n",
        "          'A man is eating pasta.',\n",
        "          'A Woman is eating Biryani.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'The baby is carried by the woman',\n",
        "          'A man is riding a horse.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'Someone in a gorilla costume is playing a set of drums.',\n",
        "          'A cheetah is running behind its prey.',\n",
        "          'A cheetah chases prey on across a field.',\n",
        "          'The cheetah is chasing a man who is riding the horse.',\n",
        "          'man and women with their baby are watching cheetah in zoo'\n",
        "          ]\n",
        "corpus_embeddings = embedder.encode(corpus)\n",
        "\n",
        "# Normalize the embeddings to unit length\n",
        "corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "BC9xCE63G0UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_embeddings[0]"
      ],
      "metadata": {
        "id": "ri3xLpcXerJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# source: https://stackoverflow.com/questions/55619176/how-to-cluster-similar-sentences-using-bert\n",
        "\n",
        "clustering_model = KMeans(n_clusters=4)\n",
        "clustering_model.fit(corpus_embeddings)\n",
        "cluster_assignment = clustering_model.labels_\n",
        "print(cluster_assignment)"
      ],
      "metadata": {
        "id": "f-pCHO7EkDKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9728213e-3be7-4735-b468-9708aa55dcb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 3 1 1 0 0 3 3 2 2 3 3 3 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_sentences = {}\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    if cluster_id not in clustered_sentences:\n",
        "        clustered_sentences[cluster_id] = []\n",
        "\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "clustered_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih-1L7bJJq0k",
        "outputId": "d0bdf4f9-eae8-40a8-d98b-5458b1d26a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ['The girl is carrying a baby.',\n",
              "  'The baby is carried by the woman',\n",
              "  'A monkey is playing drums.',\n",
              "  'Someone in a gorilla costume is playing a set of drums.',\n",
              "  'man and women with their baby are watching cheetah in zoo'],\n",
              " 1: ['Horse is eating grass.',\n",
              "  'A man is riding a horse.',\n",
              "  'A man is riding a white horse on an enclosed ground.',\n",
              "  'A cheetah is running behind its prey.',\n",
              "  'A cheetah chases prey on across a field.',\n",
              "  'The cheetah is chasing a man who is riding the horse.'],\n",
              " 2: ['A man is eating food.',\n",
              "  'A man is eating a piece of bread.',\n",
              "  'A man is eating pasta.',\n",
              "  'A Woman is eating Biryani.']}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_sentences = {}\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    if cluster_id not in clustered_sentences:\n",
        "        clustered_sentences[cluster_id] = []\n",
        "\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "clustered_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2eINiS3Sivc",
        "outputId": "90bd9c78-4a64-4ade-a824-225f199c454e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ['The girl is carrying a baby.',\n",
              "  'The baby is carried by the woman',\n",
              "  'man and women with their baby are watching cheetah in zoo'],\n",
              " 1: ['A man is eating food.',\n",
              "  'A man is eating a piece of bread.',\n",
              "  'A man is eating pasta.',\n",
              "  'A Woman is eating Biryani.'],\n",
              " 2: ['A monkey is playing drums.',\n",
              "  'Someone in a gorilla costume is playing a set of drums.'],\n",
              " 3: ['Horse is eating grass.',\n",
              "  'A man is riding a horse.',\n",
              "  'A man is riding a white horse on an enclosed ground.',\n",
              "  'A cheetah is running behind its prey.',\n",
              "  'A cheetah chases prey on across a field.',\n",
              "  'The cheetah is chasing a man who is riding the horse.']}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O5GW-zqcfsPl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}